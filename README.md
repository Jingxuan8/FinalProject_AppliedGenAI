# FinalProject_AppliedGenAI

## 1. Overview

This project implements a **voice-to-voice multi-agent assistant** built with **LangGraph**, **custom MCP tools**, and a **Streamlit UI**.  
The system accepts spoken queries, transcribes them, performs retrieval-augmented reasoning through a multi-agent pipeline, and replies with synthesized speech while displaying structured results.

The assistant supports:
- Price checking  
- Availability checking  
- Product search & recommendations  
- Safety filtering  
- RAG + Web hybrid retrieval  
- Voice input and voice output  

---

## 2. Overall Architecture

The system follows a **three-layer architecture** that cleanly separates interaction, reasoning, and tooling.

At the top layer, the **Streamlit UI** handles microphone input, automatic speech recognition (ASR), transcript display, and text-to-speech (TTS) playback. The recognized `user_text` is passed into the **LangGraph pipeline**, which acts as the core decision engine. Inside this pipeline, the **Router** interprets the query and sets intent, the **Planner** determines which tools to activate, the **Retriever** gathers evidence from both RAG and web sources, and the **Answerer** generates the final responses. All agents operate over a shared JSON state that flows through the graph.

Whenever external information is required, the pipeline issues tool calls to the **MCP Server**, which hosts structured tools such as `web_search` and `rag_search`. The MCP server returns normalized results back into the agent pipeline, completing a closed feedback loop.

This layered design makes the system modular, debuggable, and easy to extend.


## 3.Data Processing 

Data processing uses a cleaned slice of the **Amazon Product Data 2020** dataset focused on:

> `Toys & Games | Games & Accessories` (including board games, card games, dice, travel games, etc.)

All preprocessing is implemented in `ingestion.ipynb`. The notebook produces a compact catalog saved as `data/processed/games_accessories.parquet` and `games_accessories.csv`.

### 3.1. Dataset slice & filtering

1. Load the Amazon 2020 dataset from Hugging Face (`calmgoose/amazon-product-data-2020`).
2. Filter rows where the `Category` path starts with  
   `Toys & Games | Games & Accessories` (including subcategories such as Board Games, Card Games, Game Accessories, etc.).
3. Keep only products in this slice for further processing (≈ 600+ rows).

### 3.2. Column selection & standard schema

From the raw dataset we keep the columns:

- `Uniq Id`
- `Product Name`
- `Category`
- `Selling Price`
- `About Product`
- `Product Specification`
- `Technical Details`
- `Shipping Weight`
- `Product Dimensions`
- `Product Url`

These are mapped into a **standardized catalog schema**:

- `id` – from `Uniq Id`
- `title` – from `Product Name`
- `category` – from `Category`
- `price_raw` – from `Selling Price` (string, e.g. `"$19.99"`)
- `features` – concatenation of `About Product`, `Product Specification`, `Technical Details`
- `brand` – simple heuristic brand extracted from the beginning of `title`
- `rating` – placeholder (not available in this slice, set to `NaN`)
- `ingredients` – placeholder (set to empty string `""`)
- `shipping_weight` – from `Shipping Weight`
- `product_dimensions` – from `Product Dimensions`
- `product_url` – from `Product Url`

This standardized schema is what downstream RAG and MCP components consume.

### 3.3. Price parsing & sanity checks
To make price usable for filtering and ranking:
	1.	Drop rows where any of the key fields is missing:
	•	id, title, or price_raw.
	2.	Normalize price_raw into a numeric price:
	•	Remove $ and , from the string.
	•	Strip whitespace and cast to float.
	•	If parsing fails, set price = NaN.
	3.	Drop rows where price is NaN.
	4.	Remove obviously broken prices using a reasonable range for this category:
	•	Keep only rows where 2 <= price <= 300.

After these steps we get a set of products with valid IDs, titles, and sensible prices.

## 4.Build Index (Offline Vector Store for RAG)

This project uses a **private vector database** (ChromaDB) to support fast, grounded retrieval over the curated Amazon 2020 product subset. The **Build Index** step runs *offline* to convert each product record into an embedding and store it (with metadata) in a persistent vector store.

### 4.1 Script

- `build_index.py`

### 4.2 Input

`build_index.py` expects the processed parquet generated by the data-processing step:

- `data/processed/games_accessories.parquet`

### 4.3 Output

The script creates a persistent ChromaDB directory at:

- `data/vector_store/`

This directory is what the Retriever loads at query time.

### What `build_index.py` does

1. **Loads the processed subset**
   - Reads the parquet file into a DataFrame and logs its shape:
     - `Loaded processed subset: (rows, cols)`

2. **Builds “documents” for retrieval**
   - Constructs a text representation per product (e.g., title/brand/category/description-like fields, depending on what the processed file contains).

3. **Embeds documents with SentenceTransformers**
   - Uses a `SentenceTransformer` model to generate dense vectors for each product document.

4. **Writes to ChromaDB (batched)**
   - Initializes a ChromaDB client configured for persistence.
   - Adds items to a collection in batches to reduce memory usage.
   - Stores:
     - `ids`: stable unique identifiers (one per product)
     - `documents`: the text used for retrieval
     - `embeddings`: vectors from the embedding model
     - `metadatas`: lightweight fields for display/filtering (e.g., price, brand, url, etc. if present)

5. **Logs progress**
   - For each batch, prints:
     - `Inserted batch X/Y: N items`
   - Finishes with:
     - `Vector index built successfully.`


---

## 5. Graph Design

The system is structured as a **multi-agent LangGraph pipeline** where each agent operates over a shared JSON state. Each agent reads the state, appends its own outputs, and passes it forward without changing the schema.

The pipeline flow is:
1. **Router** – interprets the user query and sets intent, constraints, and a safety flag.  
2. **Planner** – decides which retrieval modes to activate (RAG, Web, or both).  
3. **Retriever** – executes tool calls and populates the state with RAG results, web results, prices, and availability.  
4. **Answerer** – cleans and ranks results, applies safety overrides if needed, and generates both paper (text) and speech outputs.

This design keeps all agents **stateless**, transparent, and reproducible. The shared JSON state acts as the single source of truth across the entire graph.


---

## 6. MCP Server & Tool Schemas

External capabilities are integrated through a custom **Model Context Protocol (MCP) server**. The server exposes two primary tools with strict JSON schemas:

### web_search
- Wraps live HTTP-based search
- Inputs: `query`, optional `num_results`
- Outputs: `title`, `url`, `snippet`, `price` (nullable), availability (inferred later)

### rag_search
- Queries a local FAISS/Chroma vector store
- Inputs: `query`, optional filters (`category`, `max_price`)
- Outputs: structured product metadata with stable identifiers

Both tools are schema-validated before execution, guaranteeing predictable and safe agent-tool interaction. Tool outputs are normalized so downstream agents can treat RAG and web results uniformly.

All tools are registered in a single MCP `server.py`, ensuring centralized control and extensibility.

---

## 7. Safety Notes

Safety is enforced at the **Router** stage. If a query is classified as unsafe, the router sets `safety_flag = True` in the shared state. The **Answerer** checks this flag before any generation and immediately returns a controlled refusal message, skipping all retrieval and reasoning.

Additional safeguards include:
- No exposure of raw URLs in speech output  
- Removal of sensitive or identifying information  
- Prevention of operational or harmful instructions  

Safety is enforced both at query interpretation and answer generation time.

---

## 8. Setup Instructions

Before running the system, configure environment variables.

1. Copy `.env.example` to `.env` in the project root.
2. Fill in:
   - `OPENAI_API_KEY` — required for LLM reasoning  
   - `SERPER_API_KEY` — required for web search  
   - `MODEL_NAME` (optional) — swap models without code changes  

Install dependencies:

pip install -r requirements.txt


## 9. Run Scripts

The system requires **two concurrent processes**: the MCP tool server and the Streamlit UI. These must be started in separate terminals from the project root directory.

### 9.1 Start MCP Server (Tool Backend)

The MCP server exposes structured tools (such as `web_search` and `rag_search`) to the LangGraph agent pipeline.

```bash
python -m mcp_server.server --transport http --host localhost --port 8765
